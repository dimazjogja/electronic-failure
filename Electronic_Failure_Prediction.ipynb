{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Electronic Failure Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1h8YVhSD2gEGQc3J5wz99jXCVw5rgbFmX",
      "authorship_tag": "ABX9TyOCPt4yZhLSOyOpcKyfp6tW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dimazjogja/electronic-failure/blob/main/Electronic_Failure_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZATpNY6GGc8"
      },
      "source": [
        "## **ELECTRONIC FAILURE PREDICTION**\n",
        "* **Background** - Predict the suspect fail parts using the 20 subtests measurement data of component. <br>\n",
        "* **Objective** - In this project we will make a prototype of application using machine learning into a real web based application using HTML / JS. <br>\n",
        "* **Dataset** - csv files of VOR dummy file contain of 20 features (Test1 to Test20 with value  (Pass as 1/ Fail as 0)), 1 target (defect part), and 1 data order (not used in prediction, will be dropped) from 99 orders. <br>\n",
        "The effort of collecting data from PDSheet (Technical Record management / Dokmee) is done manually. This is a big effort. Data available only from 2017 to 2021, there is lack of data we have, but we will try with the available data, with note that there are only REPAIR data that will be used in prediction. \n",
        "<br>\n",
        "* **Feature Engineering** - the real data measurement is represented in Volt, Ampere, Ohm, etc, but we can simplify the data into Pass (1) or Fail (0) for faster process. Please make sure that label target category is typed correctly. a different case will be considered as different label. <br>\n",
        "* **Model / Classifier** - Random Forest, Gradient Boosting, Logistic Regression <br>\n",
        "* **Prediction Type** - Supervised Learning Classification with Multi-Label Output (multi label means that the result of prediction has more than 2 data, there are various PN of parts) <br>\n",
        "* **Optimization Method** - Hyperparameter Tuning using RandomizedSearchCV, GridSearchCV <br>\n",
        "* **Metrics used** - Accuracy - 72.7% <br>\n",
        "* **Output file format** - model.pkl (Pickle). This file will then be copied into a server folder, and can be loaded from API (may use Flask, Django, or Laravel composer). \n",
        "* **Deployment** into Web Page using API, there are multiple ways to load the pkl model using Flask, Django or Laravel.\n",
        "**References**:\n",
        "\n",
        "> 1.   Flask https://towardsdatascience.com/deploy-a-machine-learning-model-using-flask-da580f84e60c\n",
        "2.   Flask https://www.linkedin.com/pulse/creating-machine-learning-web-api-flask-jonathan-wood/\n",
        "3.   Laravel https://towardsdatascience.com/how-to-deploy-machine-learning-model-in-laravel-application-5e021494d316 \n",
        "4.   Django https://medium.com/analytics-vidhya/integrating-a-machine-learning-model-with-django-79dd47eabef1\n",
        "\n",
        "* **Web development** Web development may use HTML-JAVASCRIPT using Flask REST API or Django RESTful API, OR PHP Laravel. The proptotype design in this scope is just to make a simple usable user interface, that contains:\n",
        "A search box / combo box to input partnumber group, and after an Enter, there will show the list of SubTests of the selected components, with default Pass values of each. Then the technician may click on a Toggle Button on Pass/Fail value to fill with the Unit Under Repair test result. For example, the technician found a Failure on SubTest 5, 6, 10, then just clicked the toggle button to change the value to Fail. Then Technician simply click Predict Button, the application will predict and giving results of Suspected Fail Parts.\n",
        "\n",
        "* **Future Works** Enhance the content of Web Application using component test database, including some charts to show the analytics of parts replacement this may give overview to the technician about the hisitorical data of components and parts replacement.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-Ci1wuRVixl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7050f53-b743-4e47-c757-2fabfd5f0b2e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32478CgdGY8a"
      },
      "source": [
        "### ***a. Libraries***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18ZoeAWrn9by"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "plt.style.use('default')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4IVqy66Gf46"
      },
      "source": [
        "### ***b. Preprocessing***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cW5fmviG3rr-",
        "outputId": "3f36aa1a-5025-42c8-d187-cf925fef5866"
      },
      "source": [
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Electronic Failure Prediction/CoDot2.csv\")\n",
        "\n",
        "# Variables\n",
        "Features = dataset.drop(['ORDER', 'DEFECT PARTS'], axis=1)      # Feature Matrix / Independent Variable\n",
        "Labels, Values = pd.factorize(dataset[\"DEFECT PARTS\"])          # Target Variable / Dependent Variable\n",
        "print(dataset)\n",
        "print(Features)\n",
        "print(Labels, Values)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        ORDER  TEST1  TEST2  TEST3  ...  TEST18  TEST19  TEST20     DEFECT PARTS\n",
            "0   512335678      1      1      0  ...       1       1       1  IC 850-1020-035\n",
            "1   512335679      1      1      0  ...       1       1       1  IC 850-1020-035\n",
            "2   512335680      1      1      0  ...       1       1       1  IC 850-1020-031\n",
            "3   512335681      1      1      0  ...       1       1       1  IC 850-1020-035\n",
            "4   512335682      1      1      1  ...       1       1       1  IC 850-1020-033\n",
            "..        ...    ...    ...    ...  ...     ...     ...     ...              ...\n",
            "94  512335772      1      1      0  ...       1       1       0  IC 850-1020-031\n",
            "95  512335773      1      1      0  ...       0       0       0  IC 850-1020-030\n",
            "96  512335774      1      0      1  ...       1       1       0  IC 850-1020-033\n",
            "97  512335775      1      1      0  ...       1       0       1  IC 850-1020-030\n",
            "98  512335776      1      0      0  ...       1       0       0  IC 850-1020-030\n",
            "\n",
            "[99 rows x 22 columns]\n",
            "    TEST1  TEST2  TEST3  TEST4  TEST5  ...  TEST16  TEST17  TEST18  TEST19  TEST20\n",
            "0       1      1      0      1      1  ...       1       1       1       1       1\n",
            "1       1      1      0      0      1  ...       1       1       1       1       1\n",
            "2       1      1      0      1      1  ...       1       0       1       1       1\n",
            "3       1      1      0      1      0  ...       1       1       1       1       1\n",
            "4       1      1      1      1      0  ...       1       1       1       1       1\n",
            "..    ...    ...    ...    ...    ...  ...     ...     ...     ...     ...     ...\n",
            "94      1      1      0      1      1  ...       1       0       1       1       0\n",
            "95      1      1      0      0      0  ...       0       1       0       0       0\n",
            "96      1      0      1      0      1  ...       1       0       1       1       0\n",
            "97      1      1      0      0      0  ...       1       0       1       0       1\n",
            "98      1      0      0      0      1  ...       1       1       1       0       0\n",
            "\n",
            "[99 rows x 20 columns]\n",
            "[ 0  0  1  0  2  0  0  0  3  4  4  3  4  4  3  4  3  4  4  3  5  4  5  0\n",
            "  0  1  0  2  0  0  3  3  4  4  6  4  4  6  7  6  4  4  6  5  7  5  0  8\n",
            "  1  8  2  8  8  3  3  4  4  9  4  4  9 10  9  4  4  9  5 10  5  8  8  1\n",
            "  8  2  8  8  3  3  4  4 11  4  4 11 12 11  4  4 11 12 12 12  8  8  1  8\n",
            "  2  8  8] Index(['IC 850-1020-035', 'IC 850-1020-031', 'IC 850-1020-033',\n",
            "       'MICROCIRCUIT 850-1017-020', 'MICROCIRCUIT 850-1051-230',\n",
            "       'OSCILLATOR 850-1051-210', 'MICROCIRCUIT 850-1017-021',\n",
            "       'MICROCIRCUIT 850-1051-231', 'IC 850-1020-030',\n",
            "       'MICROCIRCUIT 850-1017-022', 'MICROCIRCUIT 850-1051-232',\n",
            "       'MICROCIRCUIT 850-1017-023', 'MICROCIRCUIT 850-1051-233'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQerubibGrO6"
      },
      "source": [
        "### ***c. Model Development***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqEEhiBJm6k9"
      },
      "source": [
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(Features, Labels, test_size=0.33, random_state=42)\n",
        "\n",
        "# Random Forest\n",
        "rf0 = RandomForestClassifier()  # base model\n",
        "rf0.fit(X_train, y_train)\n",
        "# Best RS: 0.621978 using {'n_estimators': 300, 'max_features': 'sqrt', 'max_depth': 100, 'bootstrap': False}\n",
        "# Best GS: 0.623077 using {'bootstrap': True, 'max_depth': 100, 'max_features': 'sqrt', 'n_estimators': 300}\n",
        "rf = RandomForestClassifier(n_estimators=300,  max_depth=100, max_features='sqrt', bootstrap=True)  # optimized\n",
        "rf.fit(X_train, y_train)\n",
        "pickle.dump(rf, open('rf.pkl', 'wb'))\n",
        "\n",
        "# Gradient Boosting\n",
        "gb0 = OneVsRestClassifier(GradientBoostingClassifier())\n",
        "gb0.fit(X_train, y_train)\n",
        "#Best RS: 0.561538 using {'n_estimators': 50, 'max_features': 'sqrt', 'max_depth': 5, 'learning_rate': 0.1}\n",
        "#Best GS: 0.607692 using {'learning_rate': 0.1, 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 50}\n",
        "gb = OneVsRestClassifier(GradientBoostingClassifier(learning_rate=0.1, max_depth=5, max_features='sqrt', n_estimators=50))\n",
        "gb.fit(X_train, y_train)\n",
        "pickle.dump(gb, open('gb.pkl', 'wb'))\n",
        "\n",
        "# Logistic Regression\n",
        "lr0 = OneVsRestClassifier(LogisticRegression())\n",
        "lr0.fit(X_train, y_train)\n",
        "# Best RS: 0.530769 using {'solver': 'newton-cg', 'penalty': 'l2', 'max_iter': 100, 'C': 5000}\n",
        "# Best GS: 0.530769 using {'C': 7500, 'max_iter': 50, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
        "lr = OneVsRestClassifier(LogisticRegression(solver='newton-cg', penalty='l2', C=7500, max_iter=50))\n",
        "lr.fit(X_train, y_train)\n",
        "pickle.dump(lr, open('lr.pkl', 'wb'))\n",
        "\n",
        "# K Nearest Neighbour\n",
        "# Best: 0.575556 using {'metric': 'euclidean', 'weights': 'uniform'}\n",
        "knn = OneVsRestClassifier(KNeighborsClassifier(n_neighbors=1, metric='euclidean', weights='uniform'))\n",
        "knn.fit(X_train, y_train)\n",
        "pickle.dump(knn, open('knn.pkl', 'wb'))\n",
        "\n",
        "# SVC\n",
        "# Best: 0.648148 using {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf', 'probability': 'True'}\n",
        "svc = OneVsRestClassifier(SVC(C=1000, gamma='scale', kernel='rbf', probability=True))\n",
        "svc.fit(X_train, y_train)\n",
        "pickle.dump(svc, open('svc.pkl', 'wb'))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JEUxSUvHBEZ"
      },
      "source": [
        "### ***d. Model Evaluation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vj2hHDQXunnw"
      },
      "source": [
        "# RF\n",
        "y_pred_rf0 = rf0.predict(X_test)\n",
        "cm_rf0 = confusion_matrix(y_test, y_pred_rf0)\n",
        "s_acc_rf0 = round(accuracy_score(y_test, y_pred_rf0) * 100, 1)\n",
        "precision_rf0 = round(precision_score(y_test, y_pred_rf0, average='micro') * 100, 1)\n",
        "recall_rf0 = round(recall_score(y_test, y_pred_rf0, average='micro') * 100, 1)\n",
        "f1_rf0 = round(f1_score(y_test, y_pred_rf0, average='micro') * 100, 1)\n",
        "\n",
        "# RF\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "s_acc_rf = round(accuracy_score(y_test, y_pred_rf) * 100, 1)\n",
        "precision_rf = round(precision_score(y_test, y_pred_rf, average='micro') * 100, 1)\n",
        "recall_rf = round(recall_score(y_test, y_pred_rf, average='micro') * 100, 1)\n",
        "f1_rf = round(f1_score(y_test, y_pred_rf, average='micro') * 100, 1)\n",
        "\n",
        "# GB0\n",
        "y_pred_gb0 = gb0.predict(X_test)\n",
        "cm_gb0 = confusion_matrix(y_test, y_pred_gb0)\n",
        "s_acc_gb0 = round(accuracy_score(y_test, y_pred_gb0) * 100, 1)\n",
        "precision_gb0 = round(precision_score(y_test, y_pred_gb0, average='micro') * 100, 1)\n",
        "recall_gb0 = round(recall_score(y_test, y_pred_gb0, average='micro') * 100, 1)\n",
        "f1_gb0 = round(f1_score(y_test, y_pred_gb0, average='micro') * 100, 1)\n",
        "\n",
        "# GB\n",
        "y_pred_gb = gb.predict(X_test)\n",
        "cm_gb = confusion_matrix(y_test, y_pred_gb)\n",
        "s_acc_gb = round(accuracy_score(y_test, y_pred_gb) * 100, 1)\n",
        "precision_gb = round(precision_score(y_test, y_pred_gb, average='micro') * 100, 1)\n",
        "recall_gb = round(recall_score(y_test, y_pred_gb, average='micro') * 100, 1)\n",
        "f1_gb = round(f1_score(y_test, y_pred_gb, average='micro') * 100, 1)\n",
        "\n",
        "# Logistic\n",
        "y_pred_lr0 = lr0.predict(X_test)\n",
        "cm_lr0 = confusion_matrix(y_test, y_pred_lr0)\n",
        "s_acc_lr0 = round(accuracy_score(y_test, y_pred_lr0) * 100, 1)\n",
        "precision_lr0 = round(precision_score(y_test, y_pred_lr0, average='micro') * 100, 1)\n",
        "recall_lr0 = round(recall_score(y_test, y_pred_lr0, average='micro') * 100, 1)\n",
        "f1_lr0 = round(f1_score(y_test, y_pred_lr0, average='micro') * 100, 1)\n",
        "\n",
        "# Logistic Classifier\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
        "s_acc_lr = round(accuracy_score(y_test, y_pred_lr) * 100, 1)\n",
        "precision_lr = round(precision_score(y_test, y_pred_lr, average='micro') * 100, 1)\n",
        "recall_lr = round(recall_score(y_test, y_pred_lr, average='micro') * 100, 1)\n",
        "f1_lr = round(f1_score(y_test, y_pred_lr, average='micro') * 100, 1)\n",
        "\n",
        "# KNN\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "m_acc_knn = round(knn.score(X_train, y_train) * 100, 1)\n",
        "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
        "s_acc_knn = round(accuracy_score(y_test, y_pred_knn) * 100, 1)\n",
        "precision_knn = round(precision_score(y_test, y_pred_knn, average='micro') * 100, 1)\n",
        "recall_knn = round(recall_score(y_test, y_pred_knn, average='micro') * 100, 1)\n",
        "f1_knn = round(f1_score(y_test, y_pred_knn, average='micro') * 100, 1)\n",
        "\n",
        "# SVC\n",
        "y_pred_svc = svc.predict(X_test)\n",
        "cm_svc = confusion_matrix(y_test, y_pred_svc)\n",
        "s_acc_svc = round(accuracy_score(y_test, y_pred_svc) * 100, 1)\n",
        "precision_svc = round(precision_score(y_test, y_pred_svc, average='micro') * 100, 1)\n",
        "recall_svc = round(recall_score(y_test, y_pred_svc, average='micro') * 100, 1)\n",
        "f1_svc = round(f1_score(y_test, y_pred_svc, average='micro') * 100, 1)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaUEx_Vv7LF-"
      },
      "source": [
        "**Confusion matrices**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsD0_no37KpW",
        "outputId": "6457cd66-5972-4cc7-cc68-02e8261abdd0"
      },
      "source": [
        "print('Confusion Matrix of RF0')\n",
        "print(cm_rf0)\n",
        "print(s_acc_rf0)\n",
        "print(precision_rf0)\n",
        "print(recall_rf0)\n",
        "print('Confusion Matrix of RF')\n",
        "print(cm_rf)\n",
        "print(s_acc_rf)\n",
        "print(precision_rf)\n",
        "print(recall_rf)\n",
        "print('--------------------------------')\n",
        "print('Confusion Matrix of GB0')\n",
        "print(cm_gb0)\n",
        "print(s_acc_gb0)\n",
        "print(precision_gb0)\n",
        "print(recall_gb0)\n",
        "print('Confusion Matrix of GB')\n",
        "print(cm_gb)\n",
        "print(s_acc_gb)\n",
        "print(precision_gb)\n",
        "print(recall_gb)\n",
        "print('--------------------------------')\n",
        "print('Confusion Matrix of LR0')\n",
        "print(cm_lr0)\n",
        "print(s_acc_lr0)\n",
        "print(precision_lr0)\n",
        "print(recall_lr0)\n",
        "print('Confusion Matrix of LR0')\n",
        "print(cm_lr)\n",
        "print(s_acc_lr)\n",
        "print(precision_lr)\n",
        "print(recall_lr)\n",
        "print('--------------------------------')\n",
        "print('Confusion Matrix of KNN')\n",
        "print(cm_knn)\n",
        "print('--------------------------------')\n",
        "print('Confusion Matrix of SVC')\n",
        "print(cm_svc)\n",
        "print('--------------------------------')\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix of RF0\n",
            "[[3 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 4 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 6 0 0 0 3 0 0 0]\n",
            " [0 0 0 0 1 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 2 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 1 2 0 0 0 2 0 0 0]\n",
            " [0 0 0 1 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 1]]\n",
            "69.7\n",
            "69.7\n",
            "69.7\n",
            "Confusion Matrix of RF\n",
            "[[3 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 4 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 7 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 1 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 2 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 1 1 0 0 0 3 0 0 0]\n",
            " [0 0 0 1 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 1]]\n",
            "72.7\n",
            "72.7\n",
            "72.7\n",
            "--------------------------------\n",
            "Confusion Matrix of GB0\n",
            "[[3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 4 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 6 0 0 0 0 0 0 2 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 2 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 2 0 1 0 1]\n",
            " [0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1]]\n",
            "66.7\n",
            "66.7\n",
            "66.7\n",
            "Confusion Matrix of GB\n",
            "[[3 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 4 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 8 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 3 0 1 0]\n",
            " [0 0 0 1 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 1]]\n",
            "72.7\n",
            "72.7\n",
            "72.7\n",
            "--------------------------------\n",
            "Confusion Matrix of LR0\n",
            "[[3 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 4 0 0 0 0 0 0 0 0]\n",
            " [1 1 0 0 5 0 0 0 2 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 1 1 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 5 0 0 0]\n",
            " [0 0 0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0]]\n",
            "66.7\n",
            "66.7\n",
            "66.7\n",
            "Confusion Matrix of LR0\n",
            "[[3 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 4 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 6 1 0 0 1 0 1 0]\n",
            " [0 0 0 0 0 2 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 1 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 2 0 0 2]\n",
            " [0 0 0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 1]]\n",
            "69.7\n",
            "69.7\n",
            "69.7\n",
            "--------------------------------\n",
            "Confusion Matrix of KNN\n",
            "[[3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 4 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 7 1 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 1 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 2 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 1 1 2 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1]]\n",
            "--------------------------------\n",
            "Confusion Matrix of SVC\n",
            "[[3 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 4 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 7 1 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 2 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 3 0 0 1]\n",
            " [0 0 0 2 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 1]]\n",
            "--------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6iNaincG_wr"
      },
      "source": [
        "import numpy as np\n",
        "Input = [1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0]\n",
        "\n",
        "# invert back the label numbers into label values name (parts)\n",
        "parts_svc = Values[svc.predict([Input])[0]]\n",
        "parts_lr = Values[lr.predict([Input])[0]]\n",
        "parts_rf = Values[rf.predict([Input])[0]]\n",
        "parts_knn = Values[knn.predict([Input])[0]]\n",
        "parts_gb = Values[gb.predict([Input])[0]]\n",
        "\n",
        "# predict probabilities for ROC / AUC score\n",
        "prob_svc = svc.predict_proba(X_test)\n",
        "prob_lr = lr.predict_proba(X_test)\n",
        "prob_rf = rf.predict_proba(X_test)\n",
        "prob_knn = knn.predict_proba(X_test)\n",
        "prob_gb = gb.predict_proba(X_test)\n",
        "\n",
        "# roc curve for classes\n",
        "fpr1, fpr2, fpr4, fpr5, fpr6 = {}, {}, {}, {}, {}\n",
        "tpr1, tpr2, tpr4, tpr5, tpr6 = {}, {}, {}, {}, {}\n",
        "thr1, thr2, thr4, thr5, thr6 = {}, {}, {}, {}, {}\n",
        "n_class = 3\n",
        "\n",
        "for i in range(n_class):\n",
        "    fpr1[i], tpr1[i], thr1[i] = roc_curve(y_test, prob_knn[:, i], pos_label=i)\n",
        "    fpr2[i], tpr2[i], thr2[i] = roc_curve(y_test, prob_rf[:, i], pos_label=i)\n",
        "    fpr4[i], tpr4[i], thr4[i] = roc_curve(y_test, prob_gb[:, i], pos_label=i)\n",
        "    fpr5[i], tpr5[i], thr5[i] = roc_curve(y_test, prob_lr[:, i], pos_label=i)\n",
        "    fpr6[i], tpr6[i], thr6[i] = roc_curve(y_test, prob_svc[:, i], pos_label=i)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rqw8cSHo82OF"
      },
      "source": [
        "### *e. Hyper parameter Tuning*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3uZlVSc8099",
        "outputId": "fa7c27cb-83de-4609-ea2d-b67bdac83eb7"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "params  = { 'n_estimators': [100, 200, 300], \n",
        "            'max_features': ['auto', 'sqrt', 'log2'],\n",
        "            'max_depth': [10, 100, 200],\n",
        "            'bootstrap': [True, False]}\n",
        "rs = RandomizedSearchCV(estimator=RandomForestClassifier(), param_distributions=params, n_jobs=-1, scoring='accuracy', error_score=0)\n",
        "gs = GridSearchCV(estimator=RandomForestClassifier(), param_grid=params, n_jobs=-1, scoring='accuracy', error_score=0)\n",
        "rs_result = rs.fit(X_train, y_train)\n",
        "gs_result = gs.fit(X_train, y_train)\n",
        "print(\"Best RS: %f using %s\" % (rs_result.best_score_, rs_result.best_params_))\n",
        "print(\"Best GS: %f using %s\" % (gs_result.best_score_, gs_result.best_params_))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RS: 0.621978 using {'n_estimators': 300, 'max_features': 'sqrt', 'max_depth': 200, 'bootstrap': True}\n",
            "Best GS: 0.637363 using {'bootstrap': False, 'max_depth': 200, 'max_features': 'auto', 'n_estimators': 200}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOkdG5Or-I_W",
        "outputId": "46903012-9e40-44db-92d1-dff91a20be67"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "params  = { 'n_estimators': [10, 25, 50, 100], \n",
        "            'max_features': ['auto', 'sqrt'],\n",
        "            'max_depth': [3, 5, 10],\n",
        "            'learning_rate': [0.01, 0.1]}\n",
        "rs = RandomizedSearchCV(estimator=GradientBoostingClassifier(), param_distributions=params, n_jobs=-1, scoring='accuracy', error_score=0)\n",
        "gs = GridSearchCV(estimator=GradientBoostingClassifier(), param_grid=params, n_jobs=-1, scoring='accuracy', error_score=0)\n",
        "rs_result = rs.fit(X_train, y_train)\n",
        "gs_result = gs.fit(X_train, y_train)\n",
        "print(\"Best RS: %f using %s\" % (rs_result.best_score_, rs_result.best_params_))\n",
        "print(\"Best GS: %f using %s\" % (gs_result.best_score_, gs_result.best_params_))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RS: 0.546154 using {'n_estimators': 100, 'max_features': 'sqrt', 'max_depth': 3, 'learning_rate': 0.1}\n",
            "Best GS: 0.637363 using {'learning_rate': 0.1, 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 50}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9Qr-8yVBN_x",
        "outputId": "2a65b5e9-4713-4bd2-b212-1e49b295f382"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "params   = { 'solver': ['newton-cg', 'liblinear'],\n",
        "            'penalty': ['l1', 'l2'],     \n",
        "            'C': [5000, 3000, 1000],\n",
        "            'max_iter': [50, 100, 200]}\n",
        "rs = RandomizedSearchCV(estimator=LogisticRegression(), param_distributions=params, n_jobs=-1, scoring='accuracy', error_score=0)\n",
        "gs = GridSearchCV(estimator=LogisticRegression(), param_grid=params, n_jobs=-1, scoring='accuracy', error_score=0)\n",
        "rs_result = rs.fit(X_train, y_train)\n",
        "gs_result = gs.fit(X_train, y_train)\n",
        "print(\"Best RS: %f using %s\" % (rs_result.best_score_, rs_result.best_params_))\n",
        "print(\"Best GS: %f using %s\" % (gs_result.best_score_, gs_result.best_params_))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RS: 0.530769 using {'solver': 'newton-cg', 'penalty': 'l2', 'max_iter': 200, 'C': 3000}\n",
            "Best GS: 0.530769 using {'C': 5000, 'max_iter': 50, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHHUALf9HWni"
      },
      "source": [
        "### ***f. Summary Output***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xi-fn19XHVSJ",
        "outputId": "95cab503-8bb1-41db-91be-726fb79decb0"
      },
      "source": [
        "results = pd.DataFrame({\n",
        "    'Model': ['Logistic Regression', 'Random Forest', 'Gradient Boosting'],\n",
        "    'Accuracy': [s_acc_lr, s_acc_rf, s_acc_gb],\n",
        "    'Faulty Parts': [parts_lr, parts_rf, parts_gb]\n",
        "    })\n",
        "\n",
        "output = results.sort_values(by='Accuracy', ascending=False)\n",
        "output = output.reset_index(drop=True)\n",
        "print(output)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Model  Accuracy     Faulty Parts\n",
            "0        Random Forest      72.7  IC 850-1020-030\n",
            "1    Gradient Boosting      72.7  IC 850-1020-030\n",
            "2  Logistic Regression      69.7  IC 850-1020-030\n"
          ]
        }
      ]
    }
  ]
}